# -*- coding: utf-8 -*-
"""Loan Prediction Ron Cohen & Ron Yehuda.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12Ayv9Fvxc56Qpresn4xCtNFIjWzjiEW_

# Loading the data
"""

# Install necessary packages and create the Kaggle API configuration directory
import json
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy import stats


# Installing the Kaggle package
!pip install kaggle

# Set up the Kaggle API token (replace the `username` and `key` with your credentials)
api_token = {"username":"***",
             "key":"*****************"}

# Create the Kaggle configuration folder and save the API token
!mkdir /root/.kaggle/
with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)
!chmod 600 /root/.kaggle/kaggle.json

# Creating a dataset directory
!mkdir ./datasets
!mkdir ./datasets/loan-behavior

# Download the Loan Prediction Problem Dataset
!kaggle datasets download subhamjain/loan-prediction-based-on-customer-behavior -p ./datasets/loan-behavior/

# Unzip the dataset
!unzip ./datasets/loan-behavior/*.zip -d ./datasets/loan-behavior

# List the files in the directory to confirm the data has been downloaded
!ls ./datasets/loan-behavior

train_df = pd.read_csv('./datasets/loan-behavior/Training Data.csv')
test_df = pd.read_csv('./datasets/loan-behavior/Test Data.csv')

"""# 2. Methodology

## Propose an AI approach to address the problem, which could involve rule-based systems, search algorithms, machine learning models, or a combination of AI techniques

### To address the problem of credit risk assessment, we will follow a structured machine learning approach:

**Data Analysis Strategy**


*   Perform Exploratory Data Analysis (EDA) to understand feature distributions, relationships, and potential patterns
*   Analyze correlations between numerical features and the target variable (Risk_Flag)
*   Identify potential outliers and data quality issues


**Feature Engineering Approach**
*   Transform categorical variables using appropriate encoding techniques
*   Scale numerical features to ensure model compatibility
*   Handle any missing values or anomalies identified during EDA
*   Create interaction features if meaningful relationships are discovered


**Model Development**
* Split data into training and validation sets
* Implement random forests and XGBoost models.
* Use cross-validation to ensure robust model performance

**Evaluation**
* Primary metrics: accuracy, precision, recall, F1-score
* Use confusion matrices to understand error patterns
* Compare models based on both performance metrics and computational efficiency

# 3. Implementation

## Develop a prototype of the solution in an IPython notebook. The implementation should demonstrate the core functionality of the AI system.

### EDA
"""

train_df.columns = train_df.columns.str.lower()
test_df.columns = test_df.columns.str.lower()

train_df.describe().T

train_df.dtypes

train_df['married/single'].unique()

train_df['house_ownership'].unique()

train_df['car_ownership'].unique()

"""**We can apply one hot encoding in married/single, house_ownership, car_ownership column (we will do it later)**"""

numerical_data = train_df.select_dtypes(include=['int64', 'float64'])
categorical_data = train_df.select_dtypes(include=['object'])

# verify missing values.
train_df.isnull().sum()

train_df.shape

"""**Target variable distribution**"""

plt.figure(figsize=(8, 4))
train_df['risk_flag'].value_counts().plot(kind='bar')
plt.title('Distribution of Risk Flag')
plt.xlabel('Risk Flag')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

"""**Value counts for categorical columns**"""

for col in categorical_data:
    print(f"\nValue counts for {col}:")
    print(train_df[col].value_counts())

# visualize the outliers with boxplots
plt.figure(figsize=(15, 4))

plt.subplot(1, 3, 1)
sns.boxplot(data=train_df['income'])
plt.title('Income Boxplot')

plt.subplot(1, 3, 2)
sns.boxplot(data=train_df['age'])
plt.title('Age Boxplot')

plt.subplot(1, 3, 3)
sns.boxplot(data=train_df['experience'])
plt.title('Experience Boxplot')

plt.tight_layout()
plt.show()

"""**Question: What is the overall distribution of loan risk in our training dataset?**"""

plt.figure(figsize=(8, 4))
risk_counts = train_df['risk_flag'].value_counts()
plt.pie(risk_counts, labels=['Low Risk (0)', 'High Risk (1)'], autopct='%1.1f%%')
plt.title('Distribution of Loan Risk')
plt.show()

"""This pie chart shows a significant imbalance in the risk_flag distribution, with approximately 88% low-risk and 12% high-risk cases. This can lead to biased model predictions favoring the majority class.

**Question: How does income relate to loan risk?**
"""

plt.figure(figsize=(8, 4))
sns.boxplot(x='risk_flag', y='income', data=train_df)
plt.title('Income Distribution by Risk Category')
plt.ylabel('Income')
plt.xlabel('Risk Flag (0: Low Risk, 1: High Risk)')
plt.show()

print("Income statistics by risk category:")
print(train_df.groupby('risk_flag')['income'].describe())

"""The visualization reveals that higher-risk loans tend to be associated with lower income levels. There's a noticeable difference in median income between the risk categories.

**Question: What is the age distribution of borrowers and how does it relate to risk?**
"""

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.histplot(data=train_df, x='age', bins=30)
plt.title('Age Distribution of All Borrowers')

print("Age statistics by risk category:")
print(train_df.groupby('risk_flag')['age'].describe())

plt.subplot(1, 2, 2)
sns.boxplot(x='risk_flag', y='age', data=train_df)
plt.title('Age Distribution by Risk Category')
plt.show()

"""The age distribution appears to be roughly normal, with most borrowers between 25-45 years old. High-risk borrowers tend to be slightly younger on average.

**Question: How does professional experience impact loan risk?**
"""

plt.figure(figsize=(8, 4))
sns.boxplot(x='risk_flag', y='experience', data=train_df)
plt.title('Professional Experience by Risk Category')
plt.ylabel('Years of Experience')
plt.xlabel('Risk Flag (0: Low Risk, 1: High Risk)')
plt.show()

print("\nExperience statistics by risk category:")
print(train_df.groupby('risk_flag')['experience'].describe())

"""Lower-risk borrowers tend to have more years of professional experience. This makes intuitive sense as more experience often correlates with job stability and higher income.

**Question: What is the relationship between marital status and loan risk?**
"""

plt.figure(figsize=(8, 4))
marital_risk = pd.crosstab(train_df['married/single'], train_df['risk_flag'], normalize='index') * 100
marital_risk.plot(kind='bar')
plt.title('Risk Distribution by Marital Status')
plt.xlabel('Marital Status')
plt.xticks(rotation=0)
plt.ylabel('Percentage')
plt.legend(title='Risk Flag', labels=['Low Risk', 'High Risk'])
plt.show()

print("\nRisk distribution by marital status:")
print(pd.crosstab(train_df['married/single'], train_df['risk_flag'], normalize='index').round(3) * 100)

"""The analysis shows that marital status has some correlation with loan risk, with married individuals generally showing slightly lower risk rates.

**Question: What are the profession-wise risk patterns?**
"""

plt.figure(figsize=(10, 60))
prof_risk = pd.crosstab(train_df['profession'], train_df['risk_flag'], normalize='index') * 100
prof_risk.plot(kind='bar')
plt.title('Risk Distribution Across Professions')
plt.xlabel('Profession')
plt.ylabel('Percentage')
plt.xticks(fontsize=7)

plt.legend(title='Risk Flag', labels=['Low Risk', 'High Risk'])
plt.tight_layout()
plt.show()

print("\nTop 3 highest risk professions:")
print(prof_risk[1].sort_values(ascending=False).head(3))

"""Different professions show varying risk levels. Some professions demonstrate significantly higher risk rates than others, which could be related to job stability and income predictability in these sectors.

**Question: How does house ownership status correlate with loan risk?**
"""

plt.figure(figsize=(10, 5))
house_risk = pd.crosstab(train_df['house_ownership'], train_df['risk_flag'], normalize='index') * 100
house_risk.plot(kind='bar')
plt.title('Risk Distribution by House Ownership Status')
plt.xlabel('House Ownership')
plt.xticks(rotation=0)
plt.ylabel('Percentage')
plt.legend(title='Risk Flag', labels=['Low Risk', 'High Risk'])
plt.show()

print("\nRisk distribution by house ownership:")
print(house_risk.round(2))

"""The data shows that rented property residents have higher risk rates. This suggests house ownership could be a useful predictor of loan repayment ability.

**Question: Are there any geographic patterns in loan risk?**
"""

state_risk = pd.crosstab(train_df['state'], train_df['risk_flag'], normalize='index') * 100
top_risky_states = state_risk[1].sort_values(ascending=False).head(5)

plt.figure(figsize=(10, 4))
top_risky_states.plot(kind='bar')
plt.title('Top 5 States by Risk Percentage')
plt.xlabel('State')
plt.xticks(rotation=0)
plt.ylabel('Risk Percentage')
plt.show()

print("\nTop 5 states with highest risk percentages:")
print(top_risky_states.round(2))

"""There are significant geographic variations in risk rates, with some states showing notably higher risk percentages. This suggests including location-based features could improve model performance.

**Question: Is there a correlation between car ownership and risk?**
"""

car_risk = pd.crosstab(train_df['car_ownership'], train_df['risk_flag'], normalize='index') * 100
plt.figure(figsize=(8, 4))
car_risk.plot(kind='bar')
plt.title('Risk Distribution by Car Ownership')
plt.xlabel('Car Ownership')
plt.xticks(rotation=0)
plt.ylabel('Percentage')
plt.legend(title='Risk Flag', labels=['Low Risk', 'High Risk'])
plt.show()

print("\nRisk percentages by car ownership:")
print(car_risk.round(2))

"""Car ownership shows a modest correlation with risk levels, with non-car owners showing slightly higher risk rates. This could be used as a proxy for overall financial stability.

**Correlation Analysis for Numerical Features**
"""

numerical_features = ['income', 'age', 'experience', 'current_job_yrs', 'current_house_yrs']
correlation_matrix = train_df[numerical_features].corr()

sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Correlation Matrix of Numerical Features')
plt.yticks(rotation=0)
plt.show()

"""### **Feature Engineering**

**income per year experience**
"""

train_df['income_per_year_experience'] = train_df['income'] / (train_df['experience'] + 1)
test_df['income_per_year_experience'] = test_df['income'] / (test_df['experience'] + 1)

"""**Does he have assets (house and car)**"""

train_df['assets'] = ((train_df['house_ownership'] == 'Owned') &
                      (train_df['car_ownership'] == 'Yes')).astype(int)

test_df['assets'] = ((test_df['house_ownership'] == 'Owned') &
                     (test_df['car_ownership'] == 'Yes')).astype(int)

"""**income per age**"""

train_df['income_per_age'] = train_df['income'] / train_df['age']
test_df['income_per_age'] = test_df['income'] / test_df['age']

"""**job to experience ratio**"""

train_df['job_to_experience_ratio'] = train_df['current_job_yrs'] / (train_df['experience'] + 1)
test_df['job_to_experience_ratio'] = test_df['current_job_yrs'] / (test_df['experience'] + 1)

"""**data sets after Engineering**"""

# Convert to float first, then format
train_df['income_per_year_experience'] = train_df['income_per_year_experience'].astype(float).apply(lambda x: '{:.0f}'.format(x))
test_df['income_per_year_experience'] = test_df['income_per_year_experience'].astype(float).apply(lambda x: '{:.0f}'.format(x))

# Reorder columns to put risk_flag at the end
columns = ['id', 'income', 'age', 'experience', 'married/single', 'house_ownership',
           'car_ownership', 'profession', 'city', 'state', 'current_job_yrs',
           'current_house_yrs', 'income_per_year_experience', 'assets',
           'income_per_age', 'job_to_experience_ratio', 'risk_flag']

train_df = train_df[columns]
test_df = test_df[columns[:-1]]  # Remove risk_flag for test set

train_df.head()

train_df.shape

test_df

test_df.shape

train_df['income_per_year_experience'] = train_df['income_per_year_experience'].astype(float)
test_df['income_per_year_experience'] = test_df['income_per_year_experience'].astype(float)

"""### ML

**Id, city, and current_house_year column is not needed, so we can drop that features**
"""

X_train = train_df.drop(['id', 'city', 'current_house_yrs', 'assets', 'risk_flag'], axis=1)
X_test = test_df.drop(['id', 'city', 'current_house_yrs', 'assets'], axis=1)
y_train = train_df['risk_flag']

"""**Categorical and Numerical columns after Featue Engineering**"""

categorical_columns = ['married/single', 'house_ownership', 'car_ownership', 'profession', 'state']
numerical_columns = ['income', 'age', 'experience', 'current_job_yrs', 'income_per_year_experience', 'income_per_age', 'job_to_experience_ratio']

"""**Handle imbalanced data**"""

from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE

# First combine train and test data to get all unique categories
combined_df = pd.concat([X_train[categorical_columns], X_test[categorical_columns]])

# Encode categorical variables using the combined data
X_train_encoded = X_train.copy()
X_test_encoded = X_test.copy()

for col in categorical_columns:
    le = LabelEncoder()
    le.fit(combined_df[col])
    X_train_encoded[col] = le.transform(X_train[col])
    X_test_encoded[col] = le.transform(X_test[col])

# Apply SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_encoded, y_train)
X_train_encoded.dtypes

"""**Random Forest Model**"""

from sklearn.ensemble import RandomForestClassifier

# Train Random Forest model
rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')
rf_model.fit(X_train_balanced, y_train_balanced)

# Make predictions
y_pred = rf_model.predict(X_test_encoded)

"""**XGBoost Model**"""

from xgboost import XGBClassifier

# Initialize and train XGBoost model
xgb_model = XGBClassifier(
   random_state=42,
   scale_pos_weight=1,
   learning_rate=0.1,
   n_estimators=200,
   max_depth=6
)

xgb_model.fit(X_train_encoded, y_train)

# Make predictions
xgb_pred = xgb_model.predict(X_test_encoded)

"""# 4. Evaluation

## Test the solution on relevant data or scenarios. Provide a critical evaluation of its performance, discussing strengths and limitations.

**Feature importance analysis for Random Forest**
"""

feature_importance = pd.DataFrame({
    'feature': X_train_balanced.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("Top 10 Most Important Features:")
print(feature_importance.head(10))

# Create prediction dataset
sample_predictions = pd.DataFrame({
    'id': test_df['id'],
    'risk_flag': y_pred
})

"""**Confusion Metric for Random Forest**"""

# Evaluation Metrics
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix

# Calculate metrics
accuracy = accuracy_score(y_train, rf_model.predict(X_train_encoded))
precision, recall, f1, _ = precision_recall_fscore_support(y_train, rf_model.predict(X_train_encoded), average='weighted')
auc_roc = roc_auc_score(y_train, rf_model.predict_proba(X_train_encoded)[:, 1])

print(f'Accuracy: {accuracy:.3f}')
print(f'Precision: {precision:.3f}')
print(f'Recall: {recall:.3f}')
print(f'F1 Score: {f1:.3f}')
print(f'AUC-ROC: {auc_roc:.3f}')

# Plot confusion matrix
cm = confusion_matrix(y_train, rf_model.predict(X_train_encoded))
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

from sklearn.metrics import classification_report
print("Random Forest Report")
print(classification_report(y_train, rf_model.predict(X_train_encoded)))
print("We can see that we have Overfitting!")

"""**Feature importance analysis for XGBoost**"""

xgb_importance = pd.DataFrame({
   'feature': X_train_encoded.columns,
   'importance': xgb_model.feature_importances_
}).sort_values('importance', ascending=False)

print("XGBoost - Top 10 Most Important Features:")
print(xgb_importance.head(10))

"""**Confusion Metric for XGBoost**"""

# Calculate confusion matrix for XGBoost
xgb_cm = confusion_matrix(y_train, xgb_model.predict(X_train_encoded))

# Calculate metrics
accuracy = accuracy_score(y_train, xgb_model.predict(X_train_encoded))
precision, recall, f1, _ = precision_recall_fscore_support(y_train, xgb_model.predict(X_train_encoded), average='weighted')
auc_roc = roc_auc_score(y_train, xgb_model.predict_proba(X_train_encoded)[:, 1])

print(f'Accuracy: {accuracy:.3f}')
print(f'Precision: {precision:.3f}')
print(f'Recall: {recall:.3f}')
print(f'F1 Score: {f1:.3f}')
print(f'AUC-ROC: {auc_roc:.3f}')


# Plot confusion matrix
plt.figure(figsize=(8,6))
sns.heatmap(xgb_cm, annot=True, fmt='d', cmap='Blues')
plt.title('XGBoost Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

print("XGBoost Report")
print(classification_report(y_train, xgb_model.predict(X_train_encoded)))

"""**The initial 93% accuracy (Random Forest) was misleading due to overfitting.**
here we improve the Random-Forest Model by:

* Limited tree depth (max_depth=10) to prevent complex trees
* Added cross-validation to verify model generalization
"""

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

# Define improved Random Forest with regularization parameters
rf_model_improved = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    max_features='sqrt',
    random_state=42,
    class_weight='balanced'
)

# Perform k-fold cross-validation
cv_scores = cross_val_score(rf_model_improved, X_train_encoded, y_train, cv=10)
print(f"Cross-validation scores: {cv_scores}")
print(f"Average CV score: {np.mean(cv_scores):.3f} (+/- {np.std(cv_scores) * 2:.3f})")

# Train model on full training set
rf_model_improved.fit(X_train_encoded, y_train)

# Get predictions
y_pred = rf_model_improved.predict(X_train_encoded)


# Calculate metrics
accuracy = accuracy_score(y_train, rf_model_improved.predict(X_train_encoded))
precision, recall, f1, _ = precision_recall_fscore_support(y_train, rf_model_improved.predict(X_train_encoded), average='weighted')
auc_roc = roc_auc_score(y_train, rf_model_improved.predict_proba(X_train_encoded)[:, 1])

print(f'Accuracy: {accuracy:.3f}')
print(f'Precision: {precision:.3f}')
print(f'Recall: {recall:.3f}')
print(f'F1 Score: {f1:.3f}')
print(f'AUC-ROC: {auc_roc:.3f}')

"""* 0.821 accuracy means the model correctly predicts risk 82.1% of the time
* High precision (0.885) indicates very few false positives
* High recall (0.821) shows good detection of actual high-risk cases
* AUC-ROC of 0.865 indicates strong discriminative ability

**Feature importance analysis For the improve Random Forest**
"""

feature_importance = pd.DataFrame({
    'feature': X_train_encoded.columns,
    'importance': rf_model_improved.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 Most Important Features:")
print(feature_importance.head(10))

"""**Confusion Matrix For the improve Random Forest**"""

cm_improved = confusion_matrix(y_train, rf_model_improved.predict(X_train_encoded))
plt.figure(figsize=(8,6))
sns.heatmap(cm_improved, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

"""**Print classification report For improve Random Forest**"""

print("Random Forest Improved Report:")
print(classification_report(y_train, y_pred))

"""# 5. Ethical Considerations

## Discuss ethical issues related to the application of AI in the chosen domain, including biases, fairness, and societal impact.

Project Objective:
The project focused on risk prediction - predicting whether a specific customer poses a high or low risk for loan approval. This is a critical domain in the financial system that can significantly impact people's lives.
Here's an explanation of the key decisions made:

1. Feature Filtering:


  We removed the columns id, city, current_house_yrs and assets because:

  * id is a technical identifier that doesn't contribute to the model
  * city contains similar information to state but at too high a resolution that could cause overfitting
  * current_house_yrs is less relevant than house_ownership which provides better insight into financial status
  * assets is a combination of house_ownership and car_ownership which already exist in the model, and using all three together could harm the model's performance

2. Feature Engineering:
  We created several new features representing important relationships:

  * income_per_year_experience: shows how much a person earns relative to their experience
  * assets: whether a person has assets (house and car) - good indicator of financial stability
  * income_per_age: shows income level relative to age
  * job_to_experience_ratio: employment stability - how long they've stayed in the same job out of their years of experience

3. Handling Imbalanced Data:

  * The data was imbalanced (88% low risk, 12% high risk)
  * We used SMOTE to create synthetic samples of the rarer cases
  * This helps the model better learn high-risk cases


4. Model Selection:
  We used two models:

  * Random Forest: good for non-linear data and provides feature importance
  * XGBoost: known as a strong model for classification problems


5. Model Improvement:

  * We identified overfitting in the initial model
  * We improved the Random Forest by:

  * Limiting tree depth (max_depth=10)
  Adding cross-validation
  Balancing class weights


6. Results:


  * The improved model achieved approximately 82% accuracy
  * The most important features were income, age, and work experience

The project demonstrates how an ML model can assist in credit decision-making, but it's important to understand its strengths and limitations.

### Model Strengths:
**Strong Performance:**

* Accuracy of approximately 82%
* High AUC-ROC indicating good discriminative ability between cases

**Transparency:**

* The model provides feature importance
* Allows understanding of which factors influence decisions
* Decisions can be explained to customers based on existing data

####Model Limitations:
**Potential Biases:**

* May replicate historical biases in training data
* Limited to features collected in the data

**Lack of Important Data:**

* No information about previous credit history
* Missing information about existing debts
* No data on additional income or savings

**Generalization Limitations:**

* Limited to specific geographic area or culture
"""